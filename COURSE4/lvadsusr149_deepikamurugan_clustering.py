# -*- coding: utf-8 -*-
"""LVADSUSR149 DEEPIKAMURUGAN_CLUSTERING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ll3vX0Y6BOWzuZq9RC4FY74R3uRZXKN_
"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
# import statsmodels.api as sm

import warnings
warnings.filterwarnings("ignore")

from sklearn.preprocessing import LabelEncoder,MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.impute import KNNImputer
label_encoder = LabelEncoder()
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

df=pd.read_csv('/content/sample_data/Mall_Customers.csv')
df.head(10)

df.isnull().sum()

impute=KNNImputer()
for i in df.select_dtypes(include='number').columns:
  df[i]=impute.fit_transform(df[[i]])

df.duplicated().sum()

df.info()
df.drop(columns='Gender',inplace=True)

#heat map for correlation
sns.heatmap(df.select_dtypes(include = ['int64','float64']).corr(),annot=True)

#finding correlation matrix
df.select_dtypes(include = ['int64','float64']).corr()

#identifying outlier
for column in df.select_dtypes(include=['float64','int64']):
  sns.boxplot(df[[column]])

# handling the outliers using iqr
for columns in df.select_dtypes(include="number"):
  q1=df[columns].quantile(0.25)
  q3=df[columns].quantile(0.75)
  iqr=q3-q1
  lower=q1-1.5*iqr
  upper=q3+1.5*iqr
  new_df=df.loc[(df[columns]<upper)&(df[columns]>lower)]

#minmaxscaler
scaler = MinMaxScaler()
for column in df.select_dtypes(include=['float64','int64']):
  df[column] = scaler.fit_transform(df[[column]])
#standard scaler

df.head(10)

#elbow method to identify the k value
k_range = range(1,10)
sse = []
for k in k_range:
  km = KMeans(n_clusters=k)
  km.fit(df[['CustomerID','Age','Annual Income (k$)','Spending Score (1-100)']])
  sse.append(km.inertia_)
plt.xlabel('Clusters')
plt.ylabel('SSE value')
plt.plot(k_range,sse,marker='.')

#k means clustering
km=KMeans(n_clusters=6)
y_pred = km.fit_predict(df[['CustomerID','Age','Annual Income (k$)','Spending Score (1-100)']])
df['cluster'] = y_pred
df1 = df[df.cluster == 0]
df2 = df[df.cluster == 1]
df3 = df[df.cluster == 2]
df4 = df[df.cluster == 3]
df5 = df[df.cluster == 4]
df6 = df[df.cluster == 5]
plt.scatter(df1.Age,df1['Annual Income (k$)'],color='green')
plt.scatter(df2.Age,df2['Annual Income (k$)'],color='blue')
plt.scatter(df3.Age,df3['Annual Income (k$)'],color='black')
plt.scatter(df4.Age,df4['Annual Income (k$)'],color='purple')
plt.scatter(df5.Age,df5['Annual Income (k$)'],color='orange')
plt.scatter(df6.Age,df6['Annual Income (k$)'],color='yellow')
plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='red',marker='*',label='centroid')
plt.xlabel('Age')
plt.ylabel('Annual income')
plt.legend()

silhouette_score(df, y_pred)

print(df)

"""This segmentation approach lead to many strategies which helpful for increasing customer satisfaction and product sales."""